# 进程
## 相关知识
- MMU：Memory Management Unit，内存管理单元，中央处理器（CPU）中用来管理虚拟存储器、物理存储器的控制线路，同时也负责虚拟地址映射为物理地址，以及提供硬件机制的内存访问授权，多用户多进程操作系统。
- TLB：Translation Lookaside Buffer,页表缓存、转址旁路缓存，CPU的一种缓存，由内存管理单元用于改进虚拟地址到物理地址的转译速度。TLB具有固定数目的空间槽，用于存放将虚拟地址映射至物理地址的标签页表条目。

> TLB是CPU通过MMU访问主存时的缓存。

## 进程与线程
为多进程提供硬件并发透明性代价很大：
1. 分配完整的独立地址空间（内存）；
2. 切换CPU，需要保存CPU环境（包括寄存器值、程序计数器、堆栈指针等），同时，修改内存管理单元（memory management unit，MMU）的寄存器，并将转换后备缓冲器（translation lookaside buffer, TLB)中地址转换缓存内容标为无效。此外，IPC操作，需要及进行用户空间与内核空间切换，需要多次改变MMU，并刷新TLB。
3. 进程数超出主存能力，切换存在主存和磁盘交换。
    
相比较而言，**线程切换**，代价开销小：
1. 维护多个线程共享CPU所必需的最少量信息。
2. 应用人员控制并发。
3. 线程通信，可以通过共享数据完成，只在用户空间中执行。

## 线程实现
线程通过线程包方式提供，两种实现方法：
- 构造用户模式下执行的线程库；
    - 优点：用户模式下，线程生命周期管理开销小，线程上下文切换开销小；
    - 缺点：单个线程调用阻塞的系统调用，会阻塞整个进程。
- 内核管理线程并调度；
    - 优点：单线程阻塞不影响，整个进程执行情况；
    - 缺点：类似进程，生命周期管理需要在内核空间完成，开销大。

### 解决方案
- 轻量级进程(lightweight processes, LWP)，用户级线程和内核级线程混合形式，通过内核态的线程（LWP）运行用户态线程包的调度例程，寻找用户态线程执行（切换时在用户态）。
    - 优点：应用程序面对用户态的线程，对于LWP不可见；多个LWP，在内核调用阻塞时，切换LWP，重回用户态运行，开销小；适合多CPU并发。
    - 缺点：LWP由操作系统管理，开销与内核线程基本相同（次数减少）；复杂度提升。
- 调度例程激活(scheduler activation)，当线程被系统调用阻塞时，内核对线程包进程上行调用(upcall)，调用调度例程选择下一个执行线程。（**破坏分层结构**）

## 分布式系统中的线程
### 多线程客户端
浏览器，多个线程与服务器建立连接，获取资源。

### 多线程服务端
文件服务器的可行方案：
- 分发器/工作者模型，多线程服务器（一个线程接受请求，多个线程读写磁盘）；
- 单线程，阻塞读写；
- 有限状态机（并行，模拟线程和堆栈，非阻塞调用，记录请求状态）；

## 虚拟化
单个处理器模拟多个处理器机制（并行），扩展到其他资源，导致所谓虚拟化（resource virtulization）的产生。
> 虚拟化本质上是扩展或替换一个现存界面（接口）来模仿另一个系统行为。
> 虚拟化对于分布式系统提供高度的移植性和灵活性。 <br>
![](/images/ds/virtulization.PNG)

### 虚拟机系统结构
计算机系统分层结构：
1. 由机器指令组成(machine instruction)，由任何程序激起的硬件软件界面；
2. 有机器指令组成，只有特权程序（像操作系统）才能激活的硬件软件界面；
3. 由操作系统提供的系统调用（system call)组成界面；
4. 由库调用组成的界面，通常形成了所谓应用程序编程接口（application programming interface, API)。<br>
![](/images/ds/os-interfaces.PNG)

虚拟化实现方式：
1. 构建一个运行时(runtime)系统，实质提供一套抽象指令集执行程序（翻译或仿真，Java Runtime），针对进程级别。
2. 提供一种系统，做成一层完全屏蔽硬件但提供一个同样指令集（或其他硬件）的界面（VMware、Xen）。<br>
![](/images/ds/vm.PNG)

## 客户端
客户通过两种方式提供与远程服务器相交互。
1. 用户提供自身的协议，有专门网络模块联系服务。<br>
![](/images/ds/client-1.PNG)

2. 用户调用底层接口，访问远程服务。<br>
![](/images/ds/client-2.PNG)

### 客户端解决分布透明性
客户端不仅包括用户接口，此外，还可能包括部分处理和数据集工作。
- 访问透明性，由服务器生成统一接口，隐藏异构机器通信差异；
- 定位透明性、迁移透明性以及重定位透明性，关键使用一个便利的命名系统；
- 复制透明性，解决方案之一，通过客户端转发多个请求给不同服务器来实现；
- 故障透明性，一般通过客户端中间件处理，尝试重连、连接不同服务器，或者返回缓存内容。
- 并发透明性，通过专门的中介服务器实现，特别可由事务监视器实现；
- 持久性透明性，一般完全由服务器处理。

## 服务器
服务器按照组织方式划分：
1. 迭代服务器(iterative server)，自己处理请求，并且在必要情况下将响应用户；
2. 并发服务器(concurrent server)
    1. 一个线程接受请求，某个独立线程或其他进程处理请求；
    2. 每接收一个请求，派生一个新进程处理。

客户端与服务器相连需要解决的问题如下：
- 如何访问服务器端口？
    - 提供统一端口访问(HTTP 80)；
    - 守护进程设置统一端口访问，提供程序端口映射表；
    - 提供超级服务器(inetd)，接受请求，新建进程处理，处理完毕退出，节省服务器资源；
- 如何中断请求？
    - 强退；
    - 带外数据(out-of-band)，多端口监听控制/多优先级单端口控制（UNIX信号机制）；
- 如何设计服务器状态？
    - 状态无关(stateless)；
        - 软状态(soft state)信息，维护小段时间状态信息；
    - 状态相关(stateful)，文件服务器； 
    
> 考虑区分（临时的）会话(session)状态和永久状态，永久状态对于分布式系统而言，需要考虑设计相关状态维持会话，考虑容错（系统失败了采取措施）。

### 服务器集群
服务器集群的基础结构（三层）：
- 交换机，转发请求（负载均衡算法）；
- 应用服务器，处理请求；
- 数据服务器，存取数据；

服务器集群需求，导致了分布式服务器的设计。















